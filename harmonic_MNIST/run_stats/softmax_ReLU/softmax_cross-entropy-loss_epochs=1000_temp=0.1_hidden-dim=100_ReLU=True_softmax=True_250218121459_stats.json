{
    "hyperparameters": {
        "harmonic": false,
        "n": null,
        "temperature": 0.1,
        "hidden_dim": 100,
        "epochs": 1000,
        "patience": 10,
        "min_delta": 0.0001,
        "batch_size": 64,
        "learning_rate": 0.001,
        "subfolder": "softmax_ReLU",
        "run_name": null
    },
    "training_history": {
        "epoch_losses": [
            1.6339600597109114,
            0.8683967967150308,
            0.5934212264666425,
            0.4932101237843794,
            0.4486958210084484,
            0.42819303928661956,
            0.41423993371824214,
            0.4029297578865404,
            0.3935684957611027,
            0.38623030695802113,
            0.37664409038195734,
            0.37110703328906347,
            0.3691840527503729,
            0.3662037176649962,
            0.3605515798970835,
            0.35583094293787787,
            0.3524397454425089,
            0.3301594887556298,
            0.27173510442839377,
            0.2562869715967031,
            0.2503641094845622,
            0.24402766250201,
            0.23859147118654714,
            0.23342078670795793,
            0.23167248427677256,
            0.22439744762742697,
            0.22171490901965957,
            0.22584479546813824,
            0.2194257653288559,
            0.21684310281835895,
            0.2129983385997032,
            0.21475255606310772,
            0.212184753286829,
            0.20519883116917698,
            0.20685036485986924,
            0.20433667376994896,
            0.1984153868717902,
            0.1969111214167496,
            0.19432444096421764,
            0.1920517568510256,
            0.1926729813384921,
            0.19206851113166637,
            0.18592615769917903,
            0.18919582296210502,
            0.1863745351089661,
            0.18330165605618756,
            0.18269961136284033,
            0.1772879688406804,
            0.178195463312762,
            0.17633604478718504,
            0.17453842858539653,
            0.17630339958575933,
            0.16780294275193264,
            0.17225906596397922,
            0.16935988163539786,
            0.16425486317257892,
            0.17008000434533174,
            0.16367108762653462,
            0.16400011415396737,
            0.16349199792540975,
            0.16316051561750775,
            0.15492151201621238,
            0.15521384743866382,
            0.15464941515867262,
            0.15449541396519015,
            0.1512031741182147,
            0.1550383220837791,
            0.1523000739479084,
            0.15357718701317494,
            0.15009291086997242,
            0.14549662331059607,
            0.1491752424553386,
            0.14851760768544064,
            0.14457559368328882,
            0.14188725499710295,
            0.139666722686306,
            0.1466631736300552,
            0.14387379330334696,
            0.142004840165329,
            0.13972149417201465,
            0.14173197487929165,
            0.13989916826084034,
            0.14148647874704937,
            0.14120866251446162,
            0.14382579246325405,
            0.13724458345901103,
            0.139526988214839,
            0.13594674293015366,
            0.13989196347592991,
            0.13509341241764045,
            0.13848486986122469,
            0.1341179557311446,
            0.13308567106564925,
            0.1350656035703732,
            0.13316324169932206,
            0.1324346032081001,
            0.1331590753394181,
            0.13257188916897406,
            0.12935969958316162,
            0.13149142318141105,
            0.1283365016036641,
            0.12793823308956775,
            0.13020107682857876,
            0.1310425403255866,
            0.13183483725655942,
            0.12540773758446294,
            0.12464834962373794,
            0.126376766916007,
            0.12652217246877995,
            0.12467458417643108,
            0.1244712490459352,
            0.1218884468023012,
            0.12330025757974716,
            0.12616973934071596,
            0.12057076049928885,
            0.11845392515080602,
            0.12456535709513498,
            0.12018174738950853,
            0.12441284575862989,
            0.12314359555298936,
            0.12389890333292072,
            0.12232230255888628,
            0.12019791828889424,
            0.12440865340311008,
            0.1188167116976083,
            0.12366811375318369
        ],
        "early_stop_epoch": 125,
        "best_epoch": 115,
        "best_loss": 0.11845392515080602,
        "final_test_loss": 0.2585961364209652,
        "final_test_accuracy": 95.21
    },
    "timestamps": {
        "start_time": "2025-02-18 12:12:21",
        "end_time": "2025-02-18 12:14:59",
        "training_duration": "0:02:38"
    }
}