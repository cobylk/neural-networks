{
    "hyperparameters": {
        "harmonic": false,
        "n": null,
        "temperature": 0.2,
        "hidden_dim": 100,
        "epochs": 1000,
        "patience": 10,
        "min_delta": 0.0001,
        "batch_size": 64,
        "learning_rate": 0.001,
        "subfolder": "softmax_ReLU",
        "run_name": null,
        "ReLU": false,
        "softmax": true
    },
    "training_history": {
        "epoch_losses": [
            1.6482700399244263,
            0.9102636836866326,
            0.6285432112623633,
            0.5185526444840787,
            0.46434757329507675,
            0.4284097539114037,
            0.4055231642017741,
            0.387286364539727,
            0.3722319703048734,
            0.35777288315488076,
            0.30911609967316644,
            0.25908191386125745,
            0.23874126305219842,
            0.2225647311030166,
            0.21243383493552456,
            0.20226890223223898,
            0.19573311194745716,
            0.18796946710424384,
            0.18282867355474722,
            0.17927971550587143,
            0.17146834595474417,
            0.16835578509977758,
            0.16239396515669727,
            0.16103162130972407,
            0.15512493041667666,
            0.15223475471178669,
            0.1497305810832774,
            0.1475638790485034,
            0.14424520312770725,
            0.1404014026035251,
            0.13942989902789277,
            0.1391415668071619,
            0.13513330343379967,
            0.1346153478318853,
            0.13011817193266426,
            0.1262738457741911,
            0.127856928577174,
            0.12397642691792456,
            0.12270086965084806,
            0.12084589798404559,
            0.11916390933525334,
            0.12000078519583861,
            0.11790916993955909,
            0.11345738628859332,
            0.11374283824930154,
            0.11048454517272235,
            0.11050293703815703,
            0.1087851315440892,
            0.11041383716617344,
            0.10712806043276654,
            0.10462982396680567,
            0.10366393718372054,
            0.10403854888814218,
            0.1019398535448891,
            0.1024287659456449,
            0.09946755296004607,
            0.101109065724088,
            0.09904884777244316,
            0.09920468418968162,
            0.09628373104781071,
            0.09675624212230256,
            0.09726004998908559,
            0.09463122570867351,
            0.0959681457599629,
            0.09684898877846025,
            0.0934306494812213,
            0.09015726229584993,
            0.09433084685228336,
            0.0946769103991674,
            0.09508515728502544,
            0.09057272588417156,
            0.08903399078068194,
            0.09213290027360609,
            0.08860990448968052,
            0.09126913972469027,
            0.08672971600916848,
            0.08793870651665558,
            0.08747779485533264,
            0.08752835310125814,
            0.08778959776668041,
            0.08705374357332267,
            0.08556449522317917,
            0.0855242637728752,
            0.08470591387824654,
            0.08232236051582482,
            0.08422797944233902,
            0.08560136162183449,
            0.08362459865158428,
            0.08330146597325007,
            0.08684839586169323,
            0.0812984171049443,
            0.08233852183043178,
            0.08195176633642808,
            0.08337086095297927,
            0.08159508960031624,
            0.08250537809075863,
            0.08014697179760236,
            0.08180646047985027,
            0.08058539153968315,
            0.07988109089322944,
            0.07848989664326741,
            0.0804069002793391,
            0.08136370048564333,
            0.07807772112950714,
            0.07864287146466421,
            0.07640084125466946,
            0.0764382552337656,
            0.07563515738703247,
            0.07579986647869558,
            0.0773750793810354,
            0.07559531185178281,
            0.07586304322014184,
            0.0753815291128727,
            0.07780027714397099,
            0.07638360387725092,
            0.0744276160288896,
            0.07537534321968092,
            0.07373950204530012,
            0.07575054636556727,
            0.07663592311448411,
            0.07582811205369878,
            0.07443960896010068,
            0.07458242980181488,
            0.07376522206609994,
            0.07370202626729173,
            0.07096944274013436,
            0.07154118919522683,
            0.0721608544471485,
            0.07184931076268779,
            0.07419020208025745,
            0.07285876805062043,
            0.07342353639657548,
            0.06972313219599965,
            0.07100111184997171,
            0.07247067602432725,
            0.06963240505823655,
            0.07271953411787542,
            0.0690552785184417,
            0.07197133944268579,
            0.07049335559446818,
            0.07059712337750966,
            0.07109382114549881,
            0.06942003500560469,
            0.06828246116270817,
            0.06890409383853313,
            0.06885961624386627,
            0.06974321115227826,
            0.06644926645280694,
            0.06844583908761186,
            0.06858372583594133,
            0.06569612814214772,
            0.06938480338883965,
            0.06846645247709475,
            0.0677431691894685,
            0.06632239361907215,
            0.07021319627293202,
            0.06617266105275466,
            0.06588972438879406,
            0.06737979630957534,
            0.06384079224034858,
            0.06677620459461152,
            0.06621374578119865,
            0.06561992790893531,
            0.06362657326368937,
            0.06468790222846989,
            0.06698895422473693,
            0.06540920807700008,
            0.0646849325912665,
            0.06460351489438637,
            0.06631995562855195,
            0.06459398278152384,
            0.0655886052213093,
            0.06573985734317046,
            0.06576463007735514
        ],
        "early_stop_epoch": 173,
        "best_epoch": 163,
        "best_loss": 0.06362657326368937,
        "final_test_loss": 0.2513460122048855,
        "final_test_accuracy": 95.13
    },
    "timestamps": {
        "start_time": "2025-02-18 13:00:17",
        "end_time": "2025-02-18 13:04:06",
        "training_duration": "0:03:49"
    }
}