{
    "hyperparameters": {
        "harmonic": false,
        "n": null,
        "temperature": 0.04,
        "hidden_dim": 100,
        "epochs": 1000,
        "patience": 10,
        "min_delta": 0.0001,
        "batch_size": 64,
        "learning_rate": 0.001,
        "subfolder": "softmax_ReLU",
        "run_name": null,
        "ReLU": false,
        "softmax": true
    },
    "training_history": {
        "epoch_losses": [
            1.7130968596126988,
            1.0446870124924665,
            0.8065127723061962,
            0.7119862752428441,
            0.6689979234166237,
            0.6487221194864082,
            0.6184279097359318,
            0.5822053182163218,
            0.5234809807146282,
            0.49272159745952465,
            0.4890304255618978,
            0.48039180145207755,
            0.46886473350814667,
            0.4738452708892731,
            0.467980278310364,
            0.45555608996005453,
            0.45469188523381504,
            0.4436398322171748,
            0.4401098141379194,
            0.4349757902848441,
            0.4261954647582223,
            0.4204870407292838,
            0.3981809841353756,
            0.37360593319924146,
            0.3599103146683433,
            0.34383661965174334,
            0.3394753853244377,
            0.33536467753620797,
            0.33621634048487203,
            0.32831127223953893,
            0.32206523771892226,
            0.32712830459353515,
            0.315653351352,
            0.3207865728537983,
            0.3253382787839182,
            0.31224890049697873,
            0.3143335254207603,
            0.3067295638792741,
            0.314177143274308,
            0.30606327035915115,
            0.3084534262654497,
            0.30545984399217024,
            0.304485516368485,
            0.3048592319390349,
            0.3003954315331699,
            0.29534233309455643,
            0.30176867871110374,
            0.3027052879015774,
            0.2957746271870093,
            0.2954526594015899,
            0.2961108198147148,
            0.29145056809157704,
            0.2970986323975233,
            0.2906274669277452,
            0.2918387823211931,
            0.2928543981871625,
            0.29041727833640474,
            0.29365203891799396,
            0.2960909096591635,
            0.2862133544121089,
            0.2907091719644474,
            0.28788754616433115,
            0.29275696267927886,
            0.2882280471855834,
            0.2875257863808098,
            0.28454844034842847,
            0.2908617531114232,
            0.28746162031266864,
            0.2874245994301366,
            0.281671909861632,
            0.28362360575210566,
            0.2806738502006414,
            0.28366312065294813,
            0.28471490085474466,
            0.28324238137840463,
            0.27622267483537005,
            0.2777827593491975,
            0.2771677851224187,
            0.2853832225134568,
            0.27767059320151044,
            0.2734579871823666,
            0.28110200491970155,
            0.2794910829974962,
            0.27890490830691256,
            0.2770361122824172,
            0.272157960342986,
            0.27109511126714475,
            0.2720048148065869,
            0.27728882597993687,
            0.2721176087133475,
            0.2732240957364853,
            0.2686220590414396,
            0.26655557407324376,
            0.2655070957495396,
            0.2654081675083017,
            0.2659765152034284,
            0.27021400260725126,
            0.2682075594136837,
            0.2696680992222163,
            0.2611755390744855,
            0.26497541381113693,
            0.26432395005610576,
            0.2660081754527938,
            0.2584291896594168,
            0.263649754349325,
            0.2621410070046751,
            0.2578954968108996,
            0.2621672926689071,
            0.26091166219906387,
            0.2591201008271688,
            0.2578811616595112,
            0.258378852976919,
            0.26510510297774126,
            0.26337537728250027,
            0.26493212130707083,
            0.2596880578076534,
            0.2625405726148121
        ],
        "early_stop_epoch": 116,
        "best_epoch": 106,
        "best_loss": 0.2578954968108996,
        "final_test_loss": 0.3381120443344116,
        "final_test_accuracy": 93.36
    },
    "timestamps": {
        "start_time": "2025-02-18 14:04:07",
        "end_time": "2025-02-18 14:06:38",
        "training_duration": "0:02:31"
    }
}